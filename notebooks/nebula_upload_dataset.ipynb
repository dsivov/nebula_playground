{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsivov/nebula_playground/blob/main/notebooks/nebula_upload_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGLrSe4ItKbg"
      },
      "outputs": [],
      "source": [
        "!pip install -U gradient\n",
        "!pip install ipywidgets\n",
        "Please change to localhos if running 74.82.29.209 machine\n",
        "!pip install --index-url http://74.82.29.209:8090 nebula3_database==0.2.2 --trusted-host 74.82.29.209\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1RZ9Jf869Gi"
      },
      "source": [
        "API KEY - Gradient API KEY to work with Nebula Team\n",
        "Storage Provider - shared storage for all Gradient Notebooks and WorkFlows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C_EOm-MtfXX"
      },
      "outputs": [],
      "source": [
        "from gradient import DatasetsClient, DatasetVersionsClient, WorkflowsClient\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import yaml\n",
        "import requests\n",
        "import uuid\n",
        "from database.arangodb import DatabaseConnector \n",
        "\n",
        "api_key='fdcd43409325ce4d47e6dc1aa911df'\n",
        "storage_provider_id='splt47zy852oxcg'\n",
        "\n",
        "datasets_client = DatasetsClient(api_key)\n",
        "db = DatabaseConnector()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEbD_7pi7-GD"
      },
      "source": [
        "If you run this notebook locally - please change to your dataset directory with dataset movies/images\n",
        "If you run it from Google Colab - first upload your files (Files -> Create directory -> Upload) \n",
        "let's collect some inputs from you:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ_oF4ZT8o78",
        "outputId": "9e1fbfc0-b3d7-4c19-be77-5bee813486c6",
        "colab": {
          "referenced_widgets": [
            "f00b7eba2ec94e49919332a206112d8e",
            "3c9c36b572594597a2b4cbb9e5896a84",
            "27e5df4fa9344bfebe09c56a033106cb",
            "632ea66feb434358af9c714f6da9fca7"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f00b7eba2ec94e49919332a206112d8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='/datasets/dima_dataset/', description='Local Dir:', placeholder='Type something')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c9c36b572594597a2b4cbb9e5896a84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='new_dataset_01', description='Dataset:', placeholder='Type something')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27e5df4fa9344bfebe09c56a033106cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='prodemo', description='DB name:', placeholder='Type something')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "632ea66feb434358af9c714f6da9fca7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Select(description='Type:', options=('movie', 'image'), value='movie')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "_local_dataset_dir = widgets.Text(\n",
        "    value='sample_data/',\n",
        "    placeholder='Type something',\n",
        "    description='Local Dir:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "_dataset_name = widgets.Text(\n",
        "    value='new_dataset_01',\n",
        "    placeholder='Type something',\n",
        "    description='Dataset:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "_database_name = widgets.Text(\n",
        "    value='prodemo',\n",
        "    placeholder='Type something',\n",
        "    description='DB name:',\n",
        "    disabled=False\n",
        ")\n",
        "_input_type = widgets.Select(\n",
        "    options=['movie', 'image'],\n",
        "    value='movie',\n",
        "    # rows=10,\n",
        "    description='Type:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "display(_local_dataset_dir)\n",
        "display(_dataset_name)\n",
        "display(_database_name)\n",
        "display(_input_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFl_S6_qJEw6",
        "outputId": "7f6a2e7a-a921-42df-ada3-bb80f5a6e11e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use following options: \n",
            "    Dataset name:  new_dataset_01\n",
            "    Local files path:  /datasets/dima_dataset/\n",
            "    DataBase name:  prodemo\n",
            "    Input type:  image\n"
          ]
        }
      ],
      "source": [
        "print(\"Use following options: \")\n",
        "print(\"    Dataset name: \", _dataset_name.value)\n",
        "print(\"    Local files path: \", _local_dataset_dir.value)\n",
        "print(\"    DataBase name: \", _database_name.value)\n",
        "print(\"    Input type: \", _input_type.value)\n",
        "\n",
        "local_dataset_dir = _local_dataset_dir.value\n",
        "dataset_name = _dataset_name.value\n",
        "database_name = _database_name.value\n",
        "input_type = _input_type.value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stniIVL87aHb"
      },
      "source": [
        "Create new storage in Gradient Datasets Storage Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQf8h8sL6wTj"
      },
      "outputs": [],
      "source": [
        "dataset_id = datasets_client.create(\n",
        "    name=dataset_name,\n",
        "    storage_provider_id=storage_provider_id\n",
        ")\n",
        "#Create version\n",
        "datasetVersions_client = DatasetVersionsClient(api_key)\n",
        "\n",
        "version_id = datasetVersions_client.create(\n",
        "    dataset_id=dataset_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHh8JnNNCas-"
      },
      "outputs": [],
      "source": [
        "put_command = \"gradient datasets files put --id \" + dataset_id + \":\" + version_id + \" --source-path \" + local_dataset_dir + \" --apiKey \" + api_key\n",
        "commit_command = \"gradient datasets versions commit --id \"  + dataset_id + \":\" + version_id + \" --apiKey \" + api_key\n",
        "!{put_command}\n",
        "!{commit_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QewHp3d81nCS"
      },
      "source": [
        "Update pipelynes entry in database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74fLcfl81nCS",
        "outputId": "05208097-6822-419c-ce4f-3757b1bdc9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'movies': {}, 'tasks': {}, 'inputs': {'videoprocessing': {'is_async': 'false', 'movies': {'path': '/inputs/data', 'type': 'image'}, 'dataset_id': 'new_dataset_01', 'output': 'db', 'input': 'dataset', 'overwrite': 'true', 'save_movies': 'true'}}, 'id': '8787d408-4e73-4213-8112-c3c5a4a3edce', '_key': '8787d408-4e73-4213-8112-c3c5a4a3edce'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'_id': 'pipelines/8787d408-4e73-4213-8112-c3c5a4a3edce',\n",
              " '_key': '8787d408-4e73-4213-8112-c3c5a4a3edce',\n",
              " '_rev': '_fFpHZAi---'}"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wf_template = {\n",
        "  \"movies\": {},\n",
        "  \"tasks\": {},\n",
        "  \"inputs\": {\n",
        "    \"videoprocessing\": {\n",
        "      \"is_async\": 'false',\n",
        "      \"movies\": \"/inputs/data\",\n",
        "      \"dataset_id\": dataset_name,\n",
        "      \"output\": \"db\",\n",
        "      \"input\": \"dataset\",\n",
        "      \"overwrite\": 'true',\n",
        "      \"save_movies\": 'true'\n",
        "    }\n",
        "  }\n",
        "}\n",
        "pipeline_entry = wf_template\n",
        "pipeline_entry['inputs']['videoprocessing']['movies'] =  {'path':'/inputs/data', 'type': input_type}   \n",
        "pipeline_entry['id'] = str(uuid.uuid4())\n",
        "pipeline_entry['_key'] = pipeline_entry['id']\n",
        "print(pipeline_entry)\n",
        "my_db = db.connect_db(database_name)\n",
        "my_db.collection(\"pipelines\").insert(pipeline_entry)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAWZMibJ9GwW"
      },
      "source": [
        "Upload files to Gradient dataset storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uTkrPou1nCT"
      },
      "source": [
        "Done with dataset upload, lets create workflow definition \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQHN8ePy1nCT",
        "outputId": "9b1a7751-325e-42ff-a318-a7f13d2d8af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'defaults': {'env': {'PIPELINE_ID': '789957e0-a0e5-4349-bef4-7efdc7d9773c', 'REID_RESULT_PATH': '/datasets/media/services', 'ARANGO_DB': 'dima_test', 'ARANGO_HOST': '172.83.9.249', 'DATASET_NAME': 'new_dataset_01', 'DATASET_PATH': '/inputs/data/'}}, 'jobs': {'videoprocessing': {'inputs': {'data': 'workflow.inputs.data'}, 'resources': {'instance-type': 'RTX4000'}, 'uses': 'container@v1', 'env': {'EXPERT_RUN_MODE': 'task'}, 'with': {'image': 'aharonamir/nebula3_videoprocessing:9ec6a70'}}}}\n",
            "inputs:\n",
            "  data:\n",
            "    type: dataset\n",
            "    with:\n",
            "      ref: ds3a6z0eyiqex8a:weacycq\n",
            "defaults:\n",
            "  env:\n",
            "    PIPELINE_ID: 789957e0-a0e5-4349-bef4-7efdc7d9773c\n",
            "    REID_RESULT_PATH: /datasets/media/services\n",
            "    ARANGO_DB: dima_test\n",
            "    ARANGO_HOST: 172.83.9.249\n",
            "    DATASET_NAME: new_dataset_01\n",
            "    DATASET_PATH: /inputs/data/\n",
            "jobs:\n",
            "  videoprocessing:\n",
            "    inputs:\n",
            "      data: workflow.inputs.data\n",
            "    resources:\n",
            "      instance-type: RTX4000\n",
            "    uses: container@v1\n",
            "    env:\n",
            "      EXPERT_RUN_MODE: task\n",
            "    with:\n",
            "      image: aharonamir/nebula3_videoprocessing:9ec6a70\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "final_yaml_dictionary = {}\n",
        "yamldct = {}\n",
        "#Read the yml from GitHub\n",
        "URL = \"https://raw.githubusercontent.com/NEBULA3PR0JECT/nebula3_pipeline/main/upload_workflow.yaml\"\n",
        "response = requests.get(URL)\n",
        "yaml_content = response.text\n",
        "#print(yaml_content)\n",
        "yamldct = yaml.safe_load(yaml_content)\n",
        "yamldct['defaults']['env']['ARANGO_DB']=database_name\n",
        "yamldct['defaults']['env']['PIPELINE_ID']=pipeline_entry['id']\n",
        "yamldct['defaults']['env']['DATASET_NAME']=dataset_name\n",
        "yamldct['defaults']['env']['DATASET_PATH']='/inputs/data/'\n",
        "#DATASET_PATH: /inputs/data\n",
        "final_yaml_dictionary.update({'inputs': {'data': {'type':'dataset', 'with': {'ref': dataset_id + \":\" + version_id}}}})\n",
        "#print (final_yaml_dictionary)\n",
        "final_yaml_dictionary.update(yamldct)\n",
        "#print (final_yaml_dictionary)\n",
        "#yamldct['inputs']['data']['type']['with']['ref']=dataset_name\n",
        "print(yamldct)\n",
        "yaml_to_use = yaml.dump(final_yaml_dictionary, sort_keys=False)\n",
        "print(yaml_to_use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjp8gnaZ1nCT"
      },
      "outputs": [],
      "source": [
        "gradient_key = '5d88bfa5909b30076829c101624d67'\n",
        "workflow_client = WorkflowsClient(gradient_key)\n",
        "print(yamldct)\n",
        "#893f5ef9-e652-4e93-97f3-9b65f62293f8\n",
        "intermediate_value = workflow_client.run_workflow(\n",
        "    workflow_id='893f5ef9-e652-4e93-97f3-9b65f62293f8',\n",
        "    spec=final_yaml_dictionary,\n",
        "    inputs=None\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUWCO66OxMQk"
      },
      "outputs": [],
      "source": [
        "#datasets_client.delete(\n",
        "#    dataset_id=dataset_id,\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV1jJorm1nCU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}